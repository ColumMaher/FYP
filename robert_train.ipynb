{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: xxhash in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (0.12.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (1.24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\colum\\anaconda3\\envs\\fyp\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\huggingface_hub\\_login.py:188\u001b[0m, in \u001b[0;36mnotebook_login\u001b[1;34m()\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mipywidgets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwidgets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mwidgets\u001b[39;00m  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m clear_output, display  \u001b[39m# type: ignore\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipywidgets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m notebook_login\n\u001b[1;32m----> 3\u001b[0m notebook_login()\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\huggingface_hub\\_login.py:191\u001b[0m, in \u001b[0;36mnotebook_login\u001b[1;34m()\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m clear_output, display  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `notebook_login` function can only be used in a notebook (Jupyter or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m     )\n\u001b[0;32m    196\u001b[0m box_layout \u001b[39m=\u001b[39m widgets\u001b[39m.\u001b[39mLayout(\n\u001b[0;32m    197\u001b[0m     display\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflex\u001b[39m\u001b[39m\"\u001b[39m, flex_flow\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m, align_items\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcenter\u001b[39m\u001b[39m\"\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m50\u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m )\n\u001b[0;32m    200\u001b[0m token_widget \u001b[39m=\u001b[39m widgets\u001b[39m.\u001b[39mPassword(description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mToken:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ptb_text_only (C:/Users/Colum/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f)\n",
      "100%|██████████| 3/3 [00:00<00:00, 857.09it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"ptb_text_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m      2\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mroberta_on_ptb-model\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     push_to_hub\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     10\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     11\u001b[0m     args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[0;32m     12\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mdataset[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     13\u001b[0m     eval_dataset\u001b[39m=\u001b[39;49mdataset[\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     14\u001b[0m     data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\transformers\\trainer.py:497\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39m# Create clone of distant repo and output directory if needed\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[1;32m--> 497\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_git_repo(at_init\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    498\u001b[0m     \u001b[39m# In case of pull, we need to make sure every process has the latest.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\transformers\\trainer.py:3327\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[1;34m(self, at_init)\u001b[0m\n\u001b[0;32m   3325\u001b[0m     repo_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_model_id\n\u001b[0;32m   3326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m repo_name:\n\u001b[1;32m-> 3327\u001b[0m     repo_name \u001b[39m=\u001b[39m get_full_repo_name(repo_name, token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token)\n\u001b[0;32m   3329\u001b[0m \u001b[39m# Make sure the repo exists.\u001b[39;00m\n\u001b[0;32m   3330\u001b[0m create_repo(repo_name, token\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_token, private\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_private_repo, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\transformers\\utils\\hub.py:801\u001b[0m, in \u001b[0;36mget_full_repo_name\u001b[1;34m(model_id, organization, token)\u001b[0m\n\u001b[0;32m    799\u001b[0m     token \u001b[39m=\u001b[39m HfFolder\u001b[39m.\u001b[39mget_token()\n\u001b[0;32m    800\u001b[0m \u001b[39mif\u001b[39;00m organization \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 801\u001b[0m     username \u001b[39m=\u001b[39m whoami(token)[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00musername\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    803\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\huggingface_hub\\hf_api.py:801\u001b[0m, in \u001b[0;36mHfApi.whoami\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwhoami\u001b[39m(\u001b[39mself\u001b[39m, token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict:\n\u001b[0;32m    791\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[39m    Call HF API to know \"whoami\".\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39m            not provided.\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    799\u001b[0m     r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\n\u001b[0;32m    800\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/api/whoami-v2\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m--> 801\u001b[0m         headers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_hf_headers(\n\u001b[0;32m    802\u001b[0m             \u001b[39m# If `token` is provided and not `None`, it will be used by default.\u001b[39;49;00m\n\u001b[0;32m    803\u001b[0m             \u001b[39m# Otherwise, the token must be retrieved from cache or env variable.\u001b[39;49;00m\n\u001b[0;32m    804\u001b[0m             token\u001b[39m=\u001b[39;49m(token \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken \u001b[39mor\u001b[39;49;00m \u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m    805\u001b[0m         ),\n\u001b[0;32m    806\u001b[0m     )\n\u001b[0;32m    807\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m         hf_raise_for_status(r)\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\huggingface_hub\\hf_api.py:3998\u001b[0m, in \u001b[0;36mHfApi._build_hf_headers\u001b[1;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m   3995\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3996\u001b[0m     \u001b[39m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[0;32m   3997\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken\n\u001b[1;32m-> 3998\u001b[0m \u001b[39mreturn\u001b[39;00m build_hf_headers(\n\u001b[0;32m   3999\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   4000\u001b[0m     is_write_action\u001b[39m=\u001b[39;49mis_write_action,\n\u001b[0;32m   4001\u001b[0m     library_name\u001b[39m=\u001b[39;49mlibrary_name \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_name,\n\u001b[0;32m   4002\u001b[0m     library_version\u001b[39m=\u001b[39;49mlibrary_version \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_version,\n\u001b[0;32m   4003\u001b[0m     user_agent\u001b[39m=\u001b[39;49muser_agent \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_agent,\n\u001b[0;32m   4004\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:124\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    120\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(\n\u001b[0;32m    121\u001b[0m         fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[0;32m    122\u001b[0m     )\n\u001b[1;32m--> 124\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\huggingface_hub\\utils\\_headers.py:117\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[1;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mBuild headers dictionary to send in a HF Hub call.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m        If `token=True` but token is not saved locally.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m# Get auth token to send\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m token_to_send \u001b[39m=\u001b[39m get_token_to_send(token)\n\u001b[0;32m    118\u001b[0m _validate_token_to_send(token_to_send, is_write_action\u001b[39m=\u001b[39mis_write_action)\n\u001b[0;32m    120\u001b[0m \u001b[39m# Combine headers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colum\\anaconda3\\envs\\FYP\\lib\\site-packages\\huggingface_hub\\utils\\_headers.py:149\u001b[0m, in \u001b[0;36mget_token_to_send\u001b[1;34m(token)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m cached_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    150\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mToken is required (`token=True`), but no token found. You\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m need to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `huggingface-cli login` or `huggingface_hub.login`. See\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m https://huggingface.co/settings/tokens.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m     \u001b[39mreturn\u001b[39;00m cached_token\n\u001b[0;32m    157\u001b[0m \u001b[39m# Case implicit use of the token is forbidden by env variable\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"roberta_on_ptb-model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
